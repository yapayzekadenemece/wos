#ATILLIM UNÄ° HIZLI APÄ° Ã‡EKME
import httpx
import asyncio
import math
import pandas as pd
from tqdm.asyncio import tqdm
import time  # Ãœstel geri Ã§ekilme (exponential backoff) iÃ§in eklendi

# API bilgileri
BASE_URL = "https://api.clarivate.com/apis/wos-starter/v1/documents"
API_KEY = "2911c678b48cde2e576cc471cac3d27759f5328d"
HEADERS = {"X-ApiKey": API_KEY}
QUERY_PARAMS = {
    "db": "WOS",
    "q": 'OG="Atilim University" AND FPY=1900-2030',
    "limit": 50
}


async def fetch_page(client, page, total_pages, max_retries=5, base_delay=1):
    """
    Belirli bir sayfayÄ± asenkron olarak Ã§eker ve hÄ±z sÄ±nÄ±rlamasÄ± iÃ§in yeniden deneme yapar.
    """
    for attempt in range(max_retries):
        print(f"Sayfa {page}/{total_pages} Ã§ekiliyor (Deneme {attempt + 1}/{max_retries})")
        try:
            resp = await client.get(BASE_URL, headers=HEADERS, params={**QUERY_PARAMS, "page": page})
            resp.raise_for_status()  # HTTP hatalarÄ±nÄ± (4xx veya 5xx) yakala
            return resp.json().get("hits", [])
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:
                delay = min(base_delay * (2 ** attempt), 120)  # Maksimum 120 saniye beklesin
                print(f"ğŸš« Hata! Sayfa {page} iÃ§in API limitine ulaÅŸÄ±ldÄ± (429). {delay:.2f} saniye bekleniyor...")
                await asyncio.sleep(delay)
                continue  # Ä°steÄŸi yeniden dene
            else:
                print(f"ğŸš« Hata! Sayfa {page} alÄ±namadÄ±. Durum kodu: {e.response.status_code}")
                print(f"YanÄ±t iÃ§eriÄŸi:\n{e.response.text}")
                return None
        except httpx.RequestError as e:
            print(f"âŒ Sayfa {page} iÃ§in istek hatasÄ±: {e}")
            return None
        except ValueError:
            print(f"âŒ Sayfa {page} iÃ§in JSON Ã§Ã¶zme hatasÄ±. YanÄ±t metni:\n{resp.text}")
            return None
    print(f"âš ï¸ Sayfa {page}, {max_retries} denemeden sonra hala alÄ±namadÄ±. AtlanÄ±yor.")
    return None


async def main():
    """TÃ¼m verileri Ã§ekmek iÃ§in ana asenkron fonksiyon."""
    all_items = []

    async with httpx.AsyncClient() as client:
        # AdÄ±m 1: Toplam kayÄ±t sayÄ±sÄ±nÄ± doÄŸru bir ÅŸekilde hesaplamak iÃ§in ilk sayfadan meta verileri al
        try:
            initial_metadata_response = await client.get(BASE_URL, headers=HEADERS, params={**QUERY_PARAMS, "page": 1})
            initial_metadata_response.raise_for_status()
            initial_data = initial_metadata_response.json()
            total_records = initial_data.get("metadata", {}).get("total", 0)
            records_per_page = initial_data.get("metadata", {}).get("limit", 50)
            total_pages = max(1, math.ceil(total_records / records_per_page))
            print(f"Toplam kayÄ±t: {total_records}, Sayfa baÅŸÄ±na kayÄ±t: {records_per_page}, Toplam sayfa: {total_pages}")
        except (httpx.HTTPStatusError, httpx.RequestError, ValueError) as e:
            print(f"Ä°lk sayfa veya meta veri alÄ±nÄ±rken hata oluÅŸtu: {e}")
            return pd.DataFrame()  # Hata varsa boÅŸ DataFrame dÃ¶ndÃ¼r

        # TÃ¼m sayfalar iÃ§in gÃ¶revleri oluÅŸtur
        pages_to_fetch = list(range(1, total_pages + 1))

        # Ä°lerleme Ã§ubuÄŸu ile eÅŸ zamanlÄ± yÃ¼rÃ¼tme iÃ§in tqdm ile asyncio.gather kullan
        tasks = [fetch_page(client, page, total_pages, max_retries=100) for page in pages_to_fetch]

        # tqdm.asyncio.tqdm kullanarak doÄŸru bir asenkron ilerleme Ã§ubuÄŸu gÃ¶ster
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for page_data in results:
            if page_data:
                all_items.extend(page_data)

    # Veri iÅŸleme mantÄ±ÄŸÄ±nÄ±zÄ±n geri kalanÄ± aynÄ± kalÄ±r
    df = pd.json_normalize(all_items)

    columns_to_extract = [
        'uid', 'title', 'types', 'sourceTypes', 'source.sourceTitle', 'source.publishYear',
        'source.volume', 'source.issue', 'source.pages.range', 'names.authors',
        'citations', 'identifiers.doi', 'identifiers.issn', 'keywords.authorKeywords'
    ]
    # SÃ¼tunlarÄ± gÃ¼venli bir ÅŸekilde filtrele, bir sÃ¼tunun eksik olabileceÄŸi durumlarÄ± ele al
    existing_columns = [col for col in columns_to_extract if col in df.columns]
    df = df[existing_columns]

    def extract_first_list_item(value):
        if isinstance(value, list) and len(value) > 0:
            return value[0]
        return None

    # Liste olmasÄ± beklenen sÃ¼tunlara uygula
    for col in ['types', 'sourceTypes', 'keywords.authorKeywords']:
        if col in df.columns:  # SÃ¼tunun var olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            df[col] = df[col].apply(extract_first_list_item)

    # YazarlarÄ± metin olarak birleÅŸtir
    if 'names.authors' in df.columns:
        df['Author Researcher ID'] = df['names.authors'].apply(
            lambda authors: ', '.join(
                a.get('researcherId', '') for a in authors if isinstance(a, dict) and 'researcherId' in a
            ) if isinstance(authors, list) else None
        )
        df['Author Name and Surname'] = df['Author Display Name']
    else:
        df['Author Display Name'] = None
        df['Author WoS Standard'] = None
        df['Author Researcher ID'] = None
        df['Author Name and Surname'] = None

    # AtÄ±f detaylarÄ±nÄ± Ã§Ä±kar
    if 'citations' in df.columns:
        df['Citation DB'] = df['citations'].apply(
            lambda x: x[0].get('db') if isinstance(x, list) and len(x) > 0 else None
        )
        df['Citation Count'] = df['citations'].apply(
            lambda x: x[0].get('count') if isinstance(x, list) and len(x) > 0 and 'count' in x[0] else 0
        )
    else:
        df['Citation DB'] = None
        df['Citation Count'] = 0

    df['Ãœniversite AdÄ±'] = "Atilim"

    return df

if __name__ == "__main__":
    # Gerekli tÃ¼m kÃ¼tÃ¼phanelerin yÃ¼klÃ¼ olduÄŸundan emin olun:
    # pip install httpx asyncio tqdm pandas openpyxl
    print("Veri Ã§ekme baÅŸlatÄ±lÄ±yor...")
    final_df = asyncio.run(main())

    if not final_df.empty:
        print("\n--- Ã‡ekilen Veri Ã–rneÄŸi ---")
        print(final_df.head())
        file_name = "Atilim_university_17.07.2025.xlsx"
        final_df.to_excel(file_name, index=False)
        print(f"\nâœ… Veriler baÅŸarÄ±yla '{file_name}' dosyasÄ±na kaydedildi.")
    else:
        print("\nâ„¹ï¸ Veri Ã§ekilemedi veya boÅŸ DataFrame oluÅŸtu. LÃ¼tfen loglarÄ± kontrol edin.")