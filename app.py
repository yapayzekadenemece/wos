import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_community.llms import OpenAI
import openai
import logging
import re  # Regex iÃ§in eklendi
from unidecode import unidecode # TÃ¼rkÃ§e karakterler iÃ§in eklendi

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸ”‘ OpenAI API anahtarÄ±
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# API anahtarÄ± kontrolÃ¼
if not openai.api_key:
    st.error(
        "âŒ OpenAI API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin ve 'OPENAI_API_KEY' deÄŸiÅŸkenini ekleyin.")
    st.stop()

# ğŸ“Š Analiz edilebilir sÃ¼tunlar tanÄ±mÄ± (Yinelenen anahtarlar dÃ¼zeltildi)
ANALYZABLE_COLUMNS = {
    'uid': {
        'name': 'uid',
        'keywords': ['benzersiz kimlik', 'unique id', 'id', 'tanÄ±mlayÄ±cÄ±', 'yayÄ±n kimliÄŸi'],
        'description': 'YayÄ±nlara ait benzersiz kimlik bazÄ±nda analizler',
        'examples': ['ID\'si 1234 olan yayÄ±n nedir?', 'KaÃ§ farklÄ± UID var?', 'Bu UID kime ait?']
    },
    'title': {
        'name': 'title',
        'keywords': ['baÅŸlÄ±k', 'title', 'yayÄ±n adÄ±', 'eser adÄ±', 'makale baÅŸlÄ±ÄŸÄ±'],
        'description': 'YayÄ±n baÅŸlÄ±ÄŸÄ± bazÄ±nda analizler',
        'examples': ['"Machine Learning" baÅŸlÄ±klÄ± kaÃ§ yayÄ±n var?', 'En uzun baÅŸlÄ±klÄ± yayÄ±n hangisi?',
                     'BaÅŸlÄ±ÄŸÄ± "Deep Learning" olan yayÄ±nlarÄ± listele.']
    },
    'types': {
        'name': 'types',
        'keywords': ['tÃ¼r', 'type', 'kategori', 'Ã§eÅŸit', 'yayÄ±n tÃ¼rÃ¼', 'belge tÃ¼rÃ¼'],
        'description': 'YayÄ±n tÃ¼rÃ¼ bazÄ±nda analizler',
        'examples': ['KaÃ§ tane makale var?', 'Hangi yayÄ±n tÃ¼rÃ¼ en Ã§ok?', 'Konferans bildirileri nelerdir?']
    },
    'sourceTypes': {
        'name': 'sourceTypes',
        'keywords': ['kaynak tÃ¼rÃ¼', 'source type', 'dergi tÃ¼rÃ¼', 'platform'],
        'description': 'Kaynak tÃ¼rÃ¼ bazÄ±nda analizler (Ã¶rn: dergi, konferans)',
        'examples': ['Hangi kaynak tÃ¼rleri mevcut?', 'Dergi tÃ¼rÃ¼nde kaÃ§ yayÄ±n var?',
                     'Konferanslarda yayÄ±nlanan makaleler hangileri?']
    },
    'source.sourceTitle': {
        'name': 'source.sourceTitle',
        'keywords': ['dergi', 'journal', 'source', 'kaynak', 'yayÄ±n organÄ±', 'dergi adÄ±', 'kitap adÄ±'],
        'description': 'Dergi/kaynak adÄ± bazÄ±nda analizler',
        'examples': ['Hangi dergide en Ã§ok yayÄ±n var?', 'Nature dergisinde kaÃ§ yayÄ±n var?',
                     'IEEE Access dergisindeki yayÄ±nlarÄ± gÃ¶ster.']
    },
    'source.publishYear': {
        'name': 'source.publishYear',
        'keywords': ['yÄ±l', 'year', 'tarih', 'zaman', 'yayÄ±n yÄ±lÄ±', 'ne zaman'],
        'description': 'YayÄ±n yÄ±lÄ± bazÄ±nda analizler',
        'examples': ['2023 yÄ±lÄ±nda kaÃ§ yayÄ±n yapÄ±ldÄ±?', 'En Ã§ok yayÄ±n hangi yÄ±lda yapÄ±ldÄ±?',
                     'YÄ±llara gÃ¶re yayÄ±n sayÄ±larÄ±nÄ± listele.']
    },
    'source.volume': {
        'name': 'source.volume',
        'keywords': ['cilt', 'volume', 'dergi cildi', 'kaÃ§Ä±ncÄ± cilt'],
        'description': 'Dergi cilt numarasÄ± bazÄ±nda analizler',
        'examples': ['Cilt 10\'da kaÃ§ yayÄ±n var?', 'En sÄ±k kullanÄ±lan cilt numarasÄ± nedir?',
                     'Cilt 15\'teki yayÄ±nlarÄ± listele.']
    },
    'source.issue': {
        'name': 'source.issue',
        'keywords': ['sayÄ±', 'issue', 'dergi sayÄ±sÄ±', 'kaÃ§Ä±ncÄ± sayÄ±'],
        'description': 'Dergi sayÄ± numarasÄ± bazÄ±nda analizler',
        'examples': ['SayÄ± 5\'te kaÃ§ yayÄ±n var?', 'En Ã§ok yayÄ±n hangi sayÄ±da yapÄ±ldÄ±?',
                     'SayÄ± 2\'deki makaleleri gÃ¶ster.']
    },
    'source.pages.range': {
        'name': 'source.pages.range',
        'keywords': ['sayfa aralÄ±ÄŸÄ±', 'sayfa', 'pages', 'aralÄ±k', 'sayfa numarasÄ±'],
        'description': 'YayÄ±nlarÄ±n sayfa aralÄ±ÄŸÄ± bazÄ±nda analizler',
        'examples': ['10-20 sayfa aralÄ±ÄŸÄ±ndaki yayÄ±nlar hangileri?', 'Ortalama sayfa aralÄ±ÄŸÄ± nedir?',
                     'Sayfa aralÄ±ÄŸÄ± belirli olmayan yayÄ±nlarÄ± bul.']
    },
    # Yazar sÃ¼tunlarÄ± tek bir giriÅŸte birleÅŸtirildi
    'Author Display Name': { # Ana yazar sÃ¼tunu olarak Display Name kullanÄ±ldÄ±
        'name': 'Author Display Name',
        'keywords': ['yazar adÄ±', 'author display name', 'yazar', 'araÅŸtÄ±rmacÄ±', 'akademisyen', 'kim', 'hangi yazar',
                     'yayÄ±n yapan', 'kiÅŸi', 'ad soyad'], # 'ad soyad' da eklendi
        'description': 'YazarÄ±n gÃ¶rÃ¼nen adÄ± veya adÄ± ve soyadÄ± bazÄ±nda analizler',
        'examples': ['Ahmet YÄ±lmaz kaÃ§ yayÄ±n yapmÄ±ÅŸ?', 'En Ã§ok yayÄ±n yapan yazar kim?',
                     'YiÄŸit KazancÄ±oÄŸlu kaÃ§ yayÄ±nÄ± var?', 'Bu yazarÄ±n toplam yayÄ±n sayÄ±sÄ± nedir?',
                     'TaÅŸgetiren kaÃ§ yayÄ±nÄ± vardÄ±r?', 'Mehmet Demir kaÃ§ yayÄ±n yapmÄ±ÅŸ?',
                     'Bu ad ve soyad ile en Ã§ok yayÄ±n yapan kim?']
    },
    'citations': {
        'name': 'citations',
        'keywords': ['atÄ±flar', 'citations', 'referanslar', 'alÄ±ntÄ±lar'],
        'description': 'AtÄ±f bilgileri bazÄ±nda analizler (genellikle metinsel)',
        'examples': ['Hangi yayÄ±nlar en Ã§ok atÄ±f almÄ±ÅŸ?', 'Belirli bir atÄ±f metnine gÃ¶re filtrele.']
    },
    'identifiers.doi': {
        'name': 'identifiers.doi',
        'keywords': ['doi', 'tanÄ±mlayÄ±cÄ±', 'digital object identifier', 'makale kodu'],
        'description': 'DOI bazÄ±nda analizler',
        'examples': ['Bu DOI\'ye sahip yayÄ±n nedir?', 'Eksik DOI\'si olan kaÃ§ yayÄ±n var?', 'Belirli bir DOI\'yi ara.']
    },
    'identifiers.issn': {
        'name': 'identifiers.issn',
        'keywords': ['issn', 'tanÄ±mlayÄ±cÄ±', 'international standard serial number', 'dergi kodu'],
        'description': 'ISSN bazÄ±nda analizler',
        'examples': ['Bu ISSN\'e sahip dergiler hangileri?', 'En yaygÄ±n ISSN nedir?', 'ISSN\'e gÃ¶re filtrele.']
    },
    'keywords.authorKeywords': {
        'name': 'keywords.authorKeywords',
        'keywords': ['anahtar kelime', 'keyword', 'konu', 'alan', 'yazar anahtar kelimeleri', 'konu alanÄ±'],
        'description': 'Yazar anahtar kelimeleri bazÄ±nda analizler',
        'examples': ['"Machine learning" konusunda kaÃ§ yayÄ±n var?', 'En Ã§ok kullanÄ±lan anahtar kelime nedir?',
                     'Robotik ile ilgili yayÄ±nlarÄ± gÃ¶ster.']
    },
    'Author WoS Standard': {
        'name': 'Author WoS Standard',
        'keywords': ['wos yazar', 'web of science', 'wos standardÄ±', 'standardize yazar'],
        'description': 'Web of Science standart yazar adÄ± bazÄ±nda analizler',
        'examples': ['WoS standardÄ±na gÃ¶re en Ã§ok yayÄ±n yapan yazar kim?', 'Bu isme gÃ¶re kaÃ§ WoS kaydÄ± var?']
    },
    'Author Researcher ID': {
        'name': 'Author Researcher ID',
        'keywords': ['researcher id', 'yazar kimliÄŸi', 'orcid', 'kimlik numarasÄ±'],
        'description': 'Yazar Researcher ID bazÄ±nda analizler',
        'examples': ['Bu Researcher ID\'ye sahip yazar kim?', 'KaÃ§ farklÄ± Researcher ID var?',
                     'ID\'si XXX olan yazarÄ±n yayÄ±nlarÄ±.']
    },
    'Citation DB': {
        'name': 'Citation DB',
        'keywords': ['atÄ±f veritabanÄ±', 'citation database', 'db', 'veri tabanÄ±'],
        'description': 'AtÄ±f veritabanÄ± bilgisi bazÄ±nda analizler',
        'examples': ['Hangi atÄ±f veritabanlarÄ±nda yayÄ±nlar var?', 'Scopus\'ta kaÃ§ yayÄ±n listeleniyor?',
                     'Web of Science veritabanÄ±ndaki yayÄ±nlar.']
    },
    'Citation Count': {
        'name': 'Citation Count',
        'keywords': ['atÄ±f', 'citation', 'alÄ±ntÄ±', 'referans', 'atÄ±f sayÄ±sÄ±', 'toplam atÄ±f'],
        'description': 'AtÄ±f sayÄ±sÄ± bazÄ±nda analizler',
        'examples': ['En Ã§ok atÄ±f alan yayÄ±n hangisi?', 'Ortalama atÄ±f sayÄ±sÄ± kaÃ§?',
                     'YaÅŸar Ãœniversitesinin atÄ±flarÄ±nÄ±n toplamÄ± kaÃ§tÄ±r?']
    },
    'Ãœniversite AdÄ±': {
        'name': 'Ãœniversite AdÄ±',
        'keywords': ['Ã¼niversite', 'university', 'uni', 'okul', 'kurum', 'Ã¼niversite adÄ±', 'kuruluÅŸ'],
        'description': 'Ãœniversite adÄ± bazÄ±nda analizler',
        'examples': ['YaÅŸar Ãœniversitesi kaÃ§ yayÄ±n yapmÄ±ÅŸ?', 'YaÅŸar Ãœniversitesinin kaÃ§ yayÄ±nÄ± var?',
                     'Hangi Ã¼niversite en Ã§ok yayÄ±n yapÄ±yor?', 'YaÅŸar Ãœniversitesinin toplam yayÄ±n sayÄ±sÄ± kaÃ§?',
                     'Ä°zmir Ekonomi Ãœniversitesinin toplam kaÃ§ yayÄ±nÄ± vardÄ±r?'] # Yeni Ã¶rnek eklendi
    }
}

st.set_page_config(layout="wide", page_title="GPT ile YayÄ±n Analizi")
st.title("ğŸ“Š GPT ile YayÄ±n Analizi (DoÄŸal Dil Ä°le)")
st.markdown("---")


# ğŸ“ Excel dosyalarÄ±nÄ± oku
@st.cache_data
def load_excel_data():
    """Excel dosyalarÄ±nÄ± yÃ¼kle ve birleÅŸtir"""
    EXCEL_FOLDER = "excel_data/"

    if not os.path.exists(EXCEL_FOLDER):
        st.error(
            f"âŒ '{EXCEL_FOLDER}' klasÃ¶rÃ¼ bulunamadÄ±. LÃ¼tfen 'excel_data' adÄ±nda bir klasÃ¶r oluÅŸturun ve Excel dosyalarÄ±nÄ±zÄ± iÃ§ine koyun.")
        return None

    dfs = []
    loaded_files = []

    for file in os.listdir(EXCEL_FOLDER):
        if file.endswith((".xlsx", ".xls")) and not file.startswith("~$"):
            try:
                df_temp = pd.read_excel(os.path.join(EXCEL_FOLDER, file))
                dfs.append(df_temp)
                loaded_files.append(file)
                logger.info(f"âœ… {file} yÃ¼klendi ({len(df_temp)} satÄ±r)")
            except Exception as e:
                st.warning(f"âš ï¸ {file} dosyasÄ± yÃ¼klenemedi: {e}")

    if not dfs:
        st.warning("â— KlasÃ¶rde hiÃ§ .xlsx veya .xls dosyasÄ± bulunamadÄ±. LÃ¼tfen 'excel_data' klasÃ¶rÃ¼nÃ¼ze dosya ekleyin.")
        return None

    st.sidebar.success(f"ğŸ“ {len(loaded_files)} dosya yÃ¼klendi:")
    for file in loaded_files:
        st.sidebar.write(f"â€¢ {file}")

    return pd.concat(dfs, ignore_index=True)


# Veriyi yÃ¼kle
df = load_excel_data()
if df is None:
    st.stop()


# ğŸ§¹ Veri temizleme
def clean_data(df):
    """Veri temizleme iÅŸlemleri"""
    df_clean = df.copy()

    df_clean.columns = df_clean.columns.str.strip()

    # Otomatik olarak string sÃ¼tunlarÄ± tespit et ve temizle
    for col in df_clean.columns:
        if df_clean[col].dtype == 'object':
            df_clean[col] = df_clean[col].astype(str).str.strip().replace('nan', '')

    # SayÄ±sal sÃ¼tunlarÄ± temizle ve eksik deÄŸerleri doldur
    numeric_cols_to_check = [
        'Citation Count', 'source.volume', 'source.issue', 'source.publishYear'
    ]
    for col in numeric_cols_to_check:
        if col in df_clean.columns:
            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
            if col in ['Citation Count', 'source.volume', 'source.issue', 'source.publishYear']:
                df_clean[col] = df_clean[col].fillna(0).astype(int)
            else:
                df_clean[col] = df_clean[col].fillna(0)

    initial_count = len(df_clean)
    if 'title' in df_clean.columns:
        df_clean = df_clean.drop_duplicates(subset=['title'])
        removed_count = initial_count - len(df_clean)
        if removed_count > 0:
            st.info(f"ğŸ§¹ {removed_count} tekrar eden yayÄ±n kaldÄ±rÄ±ldÄ± (baÅŸlÄ±ÄŸa gÃ¶re).")

    return df_clean


df_clean = clean_data(df)

# ğŸ“Š Veri Ã¶zeti
st.subheader("ğŸ“ˆ Veri Ã–zeti")
col1, col2, col3 = st.columns(3)

with col1:
    st.metric("ğŸ“ Toplam YayÄ±n", len(df_clean))

with col2:
    if 'Ãœniversite AdÄ±' in df_clean.columns:
        unique_unis = df_clean['Ãœniversite AdÄ±'].nunique()
        st.metric("ğŸ« Ãœniversite SayÄ±sÄ±", unique_unis)
    else:
        st.metric("ğŸ« Ãœniversite SayÄ±sÄ±", "N/A")

with col3:
    if 'source.sourceTitle' in df_clean.columns:
        unique_journals = df_clean['source.sourceTitle'].nunique()
        st.metric("ğŸ“– Dergi SayÄ±sÄ±", unique_journals)
    else:
        st.metric("ğŸ“– Dergi SayÄ±sÄ±", "N/A")

# Mevcut sÃ¼tunlarÄ± gÃ¶ster
st.subheader("ğŸ“‹ Analiz Edilebilir SÃ¼tunlar")
valid_analyzable_cols = {k: v for k, v in ANALYZABLE_COLUMNS.items() if k in df_clean.columns}

available_cols_list = list(valid_analyzable_cols.keys())
missing_cols_list = [col for col in ANALYZABLE_COLUMNS.keys() if col not in df_clean.columns]

if available_cols_list:
    st.success(f"âœ… **Mevcut SÃ¼tunlar:** {', '.join(available_cols_list)}")
if missing_cols_list:
    st.warning(f"âš ï¸ **Eksik SÃ¼tunlar (Excel dosyanÄ±zda bulunmayanlar):** {', '.join(missing_cols_list)}")


# Soru tÃ¼rÃ¼ tespiti (gÃ¼ncellenmiÅŸ ve daha saÄŸlam)
def detect_question_column(question):
    """Sorudan hangi sÃ¼tunla ilgili olduÄŸunu tespit et ve niyet belirle"""
    question_lower = question.lower()
    detected_columns_and_scores = {}

    # 1. AÅŸama: Ã–zel ve yÃ¼ksek Ã¶ncelikli durumlar (Ã¼niversite, atÄ±f sayÄ±sÄ±, yazar adÄ±)
    # Ãœniversite AdÄ± tespiti
    if 'Ãœniversite AdÄ±' in df_clean.columns:
        uni_keywords = ['Ã¼niversite', 'university', 'uni', 'okul', 'kurum', 'Ã¼niversite adÄ±', 'kuruluÅŸ']
        if any(kw in question_lower for kw in uni_keywords):
            detected_columns_and_scores['Ãœniversite AdÄ±'] = 10 # En yÃ¼ksek Ã¶ncelik

    # Yazar AdÄ± tespiti
    # Yazar anahtar kelimeleri ve potansiyel bÃ¼yÃ¼k harfle baÅŸlayan isimler
    author_keywords = ['yazar', 'araÅŸtÄ±rmacÄ±', 'akademisyen', 'kim', 'yayÄ±n yapan', 'kiÅŸi', 'ad soyad']
    has_author_keyword = any(kw in question_lower for kw in author_keywords)
    potential_name_found = False

    # Regex ile bÃ¼yÃ¼k harfle baÅŸlayan kelimeleri (isimleri) bulmaya Ã§alÄ±ÅŸ
    # 'kaÃ§' gibi soru kelimelerini dÄ±ÅŸarÄ±da bÄ±rak
    clean_words = [word for word in re.findall(r'\b[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zA-ZÃ§ÄŸÄ±iÃ¶ÅŸÃ¼]*\b', question) if word.lower() not in ['kaÃ§', 'kim']]
    if len(clean_words) > 0:
        potential_name_found = True

    if has_author_keyword or potential_name_found:
        # 'Author Display Name' veya 'Author Name and Surname' sÃ¼tunu mevcutsa Ã¶ncelik ver
        if 'Author Display Name' in df_clean.columns:
            detected_columns_and_scores['Author Display Name'] = 9 # YÃ¼ksek Ã¶ncelik
        elif 'Author Name and Surname' in df_clean.columns: # EÄŸer Author Display Name yoksa veya daha az uygunsa
            detected_columns_and_scores['Author Name and Surname'] = 9

        # EÄŸer yazar soruluyorsa ve spesifik bir Ã¶lÃ§Ã¼t sÃ¼tunu yoksa, yayÄ±n sayÄ±sÄ±nÄ± saymak iÃ§in title'Ä± varsayalÄ±m
        if 'title' in df_clean.columns and 'title' not in detected_columns_and_scores:
            if 'kaÃ§ yayÄ±n' in question_lower or 'yayÄ±n sayÄ±sÄ±' in question_lower:
                detected_columns_and_scores['title'] = 1 # YazarÄ±n yayÄ±n sayÄ±sÄ±nÄ± bulmak iÃ§in uygun

    # AtÄ±f SayÄ±sÄ± tespiti
    if 'Citation Count' in df_clean.columns and any(
            kw in question_lower for kw in ANALYZABLE_COLUMNS['Citation Count']['keywords']):
        detected_columns_and_scores['Citation Count'] = 8 # YÃ¼ksek Ã¶ncelik

    # YayÄ±n YÄ±lÄ± tespiti
    if 'source.publishYear' in df_clean.columns and any(
            kw in question_lower for kw in ANALYZABLE_COLUMNS['source.publishYear']['keywords']):
        detected_columns_and_scores['source.publishYear'] = 7 # YÃ¼ksek Ã¶ncelik

    # 2. AÅŸama: DiÄŸer genel sÃ¼tunlar iÃ§in anahtar kelime tabanlÄ± tespit
    # Mevcut Ã¶ncelikleri ezmemek iÃ§in 'if col_name not in detected_columns_and_scores' kontrolÃ¼ Ã¶nemli.
    for col_name, col_info in ANALYZABLE_COLUMNS.items():
        if col_name in df_clean.columns and col_name not in detected_columns_and_scores:
            if any(keyword in question_lower for keyword in col_info['keywords']):
                # Daha genel sÃ¼tunlara dÃ¼ÅŸÃ¼k Ã¶ncelik ver
                if col_name in ['title', 'uid']: # title ve uid Ã§ok geneldir
                    detected_columns_and_scores[col_name] = max(detected_columns_and_scores.get(col_name, 0), 0.5)
                else:
                    detected_columns_and_scores[col_name] = max(detected_columns_and_scores.get(col_name, 0), 2) # Orta dÃ¼zey

    # En yÃ¼ksek puanlÄ± sÃ¼tunu seÃ§
    if detected_columns_and_scores:
        sorted_cols = sorted(detected_columns_and_scores.items(), key=lambda item: item[1], reverse=True)
        top_col_name = sorted_cols[0][0]
        return top_col_name, ANALYZABLE_COLUMNS[top_col_name]

    return None, None


# ğŸ¤– GPT ajanÄ±
# ğŸ¤– GPT ajanÄ±
@st.cache_resource
def create_agent():
    """GPT ajanÄ±nÄ± oluÅŸtur"""
    try:
        llm = OpenAI(temperature=0, model_name="gpt-3.5-turbo-instruct")
        agent = create_pandas_dataframe_agent(
            llm,
            df_clean,
            verbose=False,
            allow_dangerous_code=True,
            handle_parsing_errors=True,  # âœ… bu da doÄŸrudan verilebilir
            max_iterations=10,
            max_execution_time=30
        )
        return agent
    except Exception as e:
        st.error(
            f"âŒ GPT ajanÄ± oluÅŸturulamadÄ±: {e}. LÃ¼tfen OpenAI API anahtarÄ±nÄ±zÄ±n geÃ§erli olduÄŸundan ve internet baÄŸlantÄ±nÄ±zÄ±n olduÄŸundan emin olun.")
        return None

agent = create_agent()
if agent is None:
    st.stop()

# ğŸ’¬ Soru-cevap arayÃ¼zÃ¼
st.subheader("ğŸ¤– Soru Sor")

# Ã–rnek sorularÄ± sekmeler halinde gÃ¶ster
st.write("**ğŸ“ Ã–rnek Sorular:**")
tab_names = [info['name'] for col_name, info in ANALYZABLE_COLUMNS.items() if col_name in df_clean.columns]
# Sekme adlarÄ±nda tekrarÄ± Ã¶nlemek iÃ§in set kullanabiliriz, ancak sÄ±ralamayÄ± bozabilir.
# Bu durumda, ANALYZABLE_COLUMNS'Ä± dÃ¼zeltmek en doÄŸrusu oldu.
tabs = st.tabs(tab_names)

for i, (col_name, col_info) in enumerate(ANALYZABLE_COLUMNS.items()):
    if col_name in df_clean.columns and i < len(tabs): # Index hatasÄ±nÄ± Ã¶nlemek iÃ§in kontrol
        with tabs[i]:
            st.write(f"**{col_info['name']} iÃ§in Ã¶rnekler:**")
            for example in col_info['examples']:
                if st.button(example,
                             key=f"example_{col_name}_{example.replace(' ', '_').replace('?', '').replace('.', '').replace('"', '')}"): # Ã–zel karakterleri temizle
                    st.session_state.question = example

# KullanÄ±cÄ±dan soru al
question = st.text_input(
    "ğŸ“¥ Soru sorun:",
    value=st.session_state.get('question', ''),
    placeholder="Ã–rneÄŸin: YaÅŸar Ãœniversitesinin kaÃ§ yayÄ±nÄ± var? Veya: TaÅŸgetiren kaÃ§ yayÄ±nÄ± vardÄ±r?"
)

if question:
    target_column, col_info = detect_question_column(question)
    question_lower = question.lower()

    # Yazar bazlÄ± toplam yayÄ±n sayÄ±sÄ± sorgularÄ±nÄ± Ã¶zel olarak ele alalÄ±m
    is_author_publication_count_query = False
    if target_column in ['Author Display Name', 'Author Name and Surname'] and \
            any(kw in question_lower for kw in
                ['kaÃ§ yayÄ±nÄ± var', 'toplam yayÄ±nÄ± kaÃ§', 'yayÄ±n sayÄ±sÄ±', 'yayÄ±n sayÄ±sÄ± nedir']):
        is_author_publication_count_query = True
        st.info(
            f"ğŸ’¡ **Ã–zel Durum AlgÄ±landÄ±:** YazarÄ±n toplam yayÄ±n sayÄ±sÄ± sorgusu. '{target_column}' sÃ¼tunu kullanÄ±lacak.")

    if target_column:
        st.info(f"ğŸ¯ **Tespit edilen kategori:** **{col_info['description']}**")
        st.info(f"ğŸ” **Analiz edilecek sÃ¼tun:** **`{target_column}`**")

        instruction = ""

        if is_author_publication_count_query:
            # Yazar adÄ±nÄ± sorudan Ã§ekmek iÃ§in daha saÄŸlam bir yÃ¶ntem
            # unidecode kullanarak TÃ¼rkÃ§e karakterleri standardize et
            potential_name_parts = [unidecode(word) for word in re.findall(r'\b[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zA-ZÃ§ÄŸÄ±iÃ¶ÅŸÃ¼]*\b', question) if
                                    word.lower() not in ['kaÃ§', 'kim', 'var', 'vardÄ±r', 'adlÄ±']]
            author_name = " ".join(potential_name_parts).strip()

            if not author_name:
                # EÄŸer regex ile isim bulunamazsa, sorudan genel bir metin olarak Ã§ekmeyi dene
                # "kaÃ§ yayÄ±nÄ± var" gibi ifadeleri Ã§Ä±kararak kalanÄ± isim kabul et
                temp_name = question_lower.replace('kaÃ§ yayÄ±nÄ± var', '').replace('toplam yayÄ±nÄ± kaÃ§', '').replace(
                    'yayÄ±n sayÄ±sÄ±', '').replace('yayÄ±n sayÄ±sÄ± nedir', '').strip()
                author_name = unidecode(temp_name) # BurayÄ± da unidecode ile normalize et
                if not author_name: # Hala boÅŸsa, varsayÄ±lan bir terim kullan
                    author_name = "belirtilen yazar" # Modelin kendisi tespit etmeye Ã§alÄ±ÅŸsÄ±n

            # AjanÄ±n kullanacaÄŸÄ± prompt
            instruction = f"""
            Ã‡OK Ã–NEMLÄ° KURALLAR:

            1. KullanÄ±cÄ±nÄ±n sorusu '{author_name}' adlÄ± yazarÄ±n toplam yayÄ±n sayÄ±sÄ±yla ilgili.
            2. Bu soruyu cevaplamak iÃ§in SADECE '{target_column}' sÃ¼tununu kullan.
            3. DataFrame'i '{author_name}' ismini iÃ§eren yayÄ±nlarÄ± bulmak iÃ§in filtrele. Arama yaparken, hem aranan terimi hem de sÃ¼tun iÃ§eriÄŸini TÃ¼rkÃ§e karakterlerden arÄ±ndÄ±rarak (unidecode kullanarak) ve bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z (case=False) bir ÅŸekilde karÅŸÄ±laÅŸtÄ±r. BoÅŸ deÄŸerleri (na=False) yok say.
            4. Daha sonra, bu filtrelenmiÅŸ yayÄ±nlarÄ±n SATIR SAYISINI (Ã¶rneÄŸin `.shape[0]` veya `len()`) dÃ¶ndÃ¼r.
            5. EÄŸer belirtilen yazara ait yayÄ±n bulunamazsa, uygun bir mesajla yanÄ±t ver.
            6. CevabÄ±nÄ± TÃ¼rkÃ§e ver ve sayÄ±sal sonucu aÃ§Ä±kÃ§a belirt.
            7. **SakÄ±n herhangi bir Python kodu Ã¼retme veya kod ÅŸablonu verme.**

            DataFrame adÄ±: df
            Hedef sÃ¼tun: {target_column}

            KullanÄ±cÄ± sorusu: {question}

            Åimdi bu kurallara gÃ¶re soruyu cevapla.
            """
        elif "en Ã§ok atÄ±f aldÄ±ÄŸÄ± yayÄ±n" in question_lower or "en Ã§ok atÄ±f alan yayÄ±n" in question_lower:
            st.info(
                "ğŸ’¡ **Ã–zel Durum AlgÄ±landÄ±:** 'En Ã§ok atÄ±f alan yayÄ±n' sorgusu algÄ±landÄ±. Analiz 'Citation Count' ve 'title' sÃ¼tunlarÄ±nÄ± iÃ§erecektir.")

            uni_filter_term = ""
            # unidecode ile Ã¼niversite adlarÄ±nÄ± normalize et
            if "yaÅŸar Ã¼niversitesi" in unidecode(question_lower):
                uni_filter_term = "yaÅŸar Ã¼niversitesi"
            elif "yaÅŸar" in unidecode(question_lower):
                uni_filter_term = "yaÅŸar"
            elif "izmir ekonomi Ã¼niversitesi" in unidecode(question_lower):
                uni_filter_term = "izmir ekonomi Ã¼niversitesi"
            elif "izmir ekonomi" in unidecode(question_lower):
                uni_filter_term = "izmir ekonomi"

            uni_filter_clause = ""
            if uni_filter_term and 'Ãœniversite AdÄ±' in df_clean.columns:
                uni_filter_clause = f"""
                from unidecode import unidecode
                search_uni_normalized = unidecode('{uni_filter_term}').lower()
                df_filtered = df[df['Ãœniversite AdÄ±'].astype(str).apply(lambda x: search_uni_normalized in unidecode(str(x)).lower() if pd.notna(x) else False)]
                if not df_filtered.empty:
                    most_cited = df_filtered.loc[df_filtered['Citation Count'].idxmax()]
                    print(f"En Ã§ok atÄ±f alan yayÄ±n ({uni_filter_term}): {{most_cited['title']}} (AtÄ±f SayÄ±sÄ±: {{most_cited['Citation Count']}})")
                else:
                    print(f"'{uni_filter_term}' Ã¼niversitesine ait yayÄ±n bulunamadÄ±.")
                """
            else:
                uni_filter_clause = """
                most_cited = df.loc[df['Citation Count'].idxmax()]
                print(f"En Ã§ok atÄ±f alan yayÄ±n: {most_cited['title']} (AtÄ±f SayÄ±sÄ±: {most_cited['Citation Count']})")
                """

            instruction = f"""
            Ã‡OK Ã–NEMLÄ° KURALLAR:

            1. KullanÄ±cÄ±nÄ±n sorusu "en Ã§ok atÄ±f alan yayÄ±n" ile ilgili.
            2. Bu soruyu cevaplamak iÃ§in 'Citation Count' ve 'title' sÃ¼tunlarÄ±nÄ± kullanmalÄ±sÄ±n. EÄŸer Ã¼niversite belirtilmiÅŸse 'Ãœniversite AdÄ±' sÃ¼tununu da kullan.
            3. Ã–ncelikle eÄŸer bir Ã¼niversite adÄ± belirtilmiÅŸse (Ã¶rn. 'YaÅŸar Ãœniversitesi'), DataFrame'i bu Ã¼niversiteye gÃ¶re filtrele. TÃ¼rkÃ§e karakterleri de gÃ¶z Ã¶nÃ¼nde bulundurarak unidecode ile normalizasyon yap.
            4. Sonra, bu filtrelenmiÅŸ verideki 'Citation Count' sÃ¼tununa gÃ¶re azalan sÄ±rada sÄ±rala.
            5. En yÃ¼ksek atÄ±f sayÄ±sÄ±na sahip yayÄ±nÄ±n BAÅLIÄINI ('title' sÃ¼tunu) ve ATIF SAYISINI ('Citation Count' sÃ¼tununu) dÃ¶ndÃ¼r.
            6. EÄŸer birden fazla yayÄ±n aynÄ± en yÃ¼ksek atÄ±f sayÄ±sÄ±na sahipse, sadece ilkini dÃ¶ndÃ¼rmen yeterlidir.
            7. Sadece bu sÃ¼tunlarÄ± kullan ve baÅŸka sÃ¼tunlara odaklanma.

            DataFrame adÄ±: df
            Hedef sÃ¼tunlar: Citation Count, title, (isteÄŸe baÄŸlÄ± olarak Ãœniversite AdÄ±)

            Ã–rnek kod ÅŸablonu:
            {uni_filter_clause}

            KullanÄ±cÄ± sorusu: {question}

            CevabÄ±nÄ± TÃ¼rkÃ§e ver ve yayÄ±nÄ±n baÅŸlÄ±ÄŸÄ±nÄ± ve atÄ±f sayÄ±sÄ±nÄ± aÃ§Ä±kÃ§a belirt.
            """
            university_name = "yaÅŸar"
            yasar_count = \
            df_clean[df_clean['Ãœniversite AdÄ±'].astype(str).str.lower().str.contains(university_name)].shape[0]
            # Ãœniversite toplam yayÄ±n sayÄ±sÄ± sorgusu iÃ§in Ã¶zel instruction
            uni_name_match = re.search(r'(?P<uni>[\w\sÄŸÃ¼ÅŸÃ¶Ã§Ä±Ä°]+)\s+Ã¼niversite(?:si)?(?:sinin)?', question_lower)
            university_name = ""
            if uni_name_match:
                university_name = unidecode(uni_name_match.group('uni').strip())
            else:
                # EÄŸer regex ile bulunamazsa, anahtar kelimeleri Ã§Ä±kararak geri kalanÄ± Ã¼niversite adÄ± olarak al
                temp_uni_name = question_lower.replace('kaÃ§ yayÄ±nÄ± var', '').replace('yayÄ±n sayÄ±sÄ±', '').replace('toplam yayÄ±n', '').strip()
                university_name = unidecode(temp_uni_name)
                if not university_name:
                    university_name = "belirtilen Ã¼niversite"

            instruction = f"""
            Ã‡OK Ã–NEMLÄ° KURALLAR:

            1. KullanÄ±cÄ±nÄ±n sorusu '{university_name}' adlÄ± Ã¼niversitenin toplam yayÄ±n sayÄ±sÄ±yla ilgili.
            2. Bu soruyu cevaplamak iÃ§in SADECE '{target_column}' sÃ¼tununu kullanmalÄ±sÄ±n.
            3. Ã–ncelikle DataFrame'i '{university_name}' ismini iÃ§eren yayÄ±nlarÄ± bulmak iÃ§in filtrele (unidecode kullanarak TÃ¼rkÃ§e karakterleri normalize et, bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z ve boÅŸ deÄŸerleri yok sayarak).
            4. Daha sonra, bu filtrelenmiÅŸ yayÄ±nlarÄ±n SATIR SAYISINI (Ã¶rneÄŸin `.shape[0]` veya `len()`) dÃ¶ndÃ¼r.
            5. EÄŸer belirtilen Ã¼niversiteye ait yayÄ±n bulunamazsa, uygun bir mesajla yanÄ±t ver.
            6. CevabÄ±nÄ± TÃ¼rkÃ§e ver ve sayÄ±sal sonucu aÃ§Ä±kÃ§a belirt.

            DataFrame adÄ±: df
            Hedef sÃ¼tun: {target_column}

            Ã–rnek kod ÅŸablonu:
            from unidecode import unidecode
            search_uni_normalized = unidecode('{university_name}').lower()
            df_filtered = df[df['{target_column}'].astype(str).apply(lambda x: search_uni_normalized in unidecode(str(x)).lower() if pd.notna(x) else False)]
            if not df_filtered.empty:
                print(f"'{university_name}' adlÄ± Ã¼niversitenin toplam {{len(df_filtered)}} yayÄ±nÄ± bulunmaktadÄ±r.")
            else:
                print(f"'{university_name}' adlÄ± Ã¼niversiteye ait yayÄ±n bulunamadÄ±.")

            KullanÄ±cÄ± sorusu: {question}

            Åimdi bu kurallara gÃ¶re soruyu cevapla.
            """
        else:  # DiÄŸer genel sorgular iÃ§in mevcut talimat
            instruction = f"""
            Ã‡OK Ã–NEMLÄ° KURALLAR:

            1. SADECE '{target_column}' sÃ¼tununa odaklan.
            2. DÄ°ÄER TÃœM SÃœTUNLARI GÃ–RMEZDEN GEL.
            3. Filtreleme veya hesaplama yaparken sadece bu sÃ¼tunu kullan.
            4. Bu sÃ¼tun dÄ±ÅŸÄ±ndaki hiÃ§bir sÃ¼tuna bakma.
            5. CevabÄ±nÄ± TÃ¼rkÃ§e ver ve mÃ¼mkÃ¼nse sayÄ±sal sonuÃ§larÄ± gÃ¶ster.

            DataFrame adÄ±: df
            Hedef sÃ¼tun: {target_column}
            Veri tipi: {df_clean[target_column].dtype}

            # Ã–nemli Ã‡Ä±karsama ve Talimatlar:
            # EÄŸer kullanÄ±cÄ±nÄ±n sorusu "toplam yayÄ±n", "kaÃ§ yayÄ±n", "yayÄ±n sayÄ±sÄ±" gibi ifadeler iÃ§eriyorsa,
            # ve hedef sÃ¼tun 'Ãœniversite AdÄ±' veya 'title' gibi yayÄ±nlarÄ± saymaya uygun bir sÃ¼tun ise,
            # ilgili filtrelenmiÅŸ DataFrame'in SATIR SAYISINI (Ã¶rneÄŸin .shape[0] veya len()) dÃ¶ndÃ¼r.
            # Ã–rneÄŸin: df[df['Ãœniversite AdÄ±'].str.contains('yaÅŸar', case=False, na=False)].shape[0]

            # EÄŸer kullanÄ±cÄ±nÄ±n sorusu "toplam atÄ±f", "atÄ±flarÄ±nÄ±n toplamÄ±" gibi ifadeler iÃ§eriyorsa,
            # ve hedef sÃ¼tun 'Citation Count' ise, bu sÃ¼tundaki sayÄ±sal deÄŸerlerin TOPLAMINI (SUM) hesapla.
            # Ã–rneÄŸin: df[df['Ãœniversite AdÄ±'].str.contains('yaÅŸar', case=False, na=False)]['Citation Count'].sum()

            KullanÄ±cÄ± sorusu: {question}

            Åimdi bu kurallara gÃ¶re soruyu cevapla.
            """

        with st.spinner("ğŸ¤– GPT analiz ediyor..."):
            try:
                response = agent.run(instruction)

                st.success("ğŸ§  GPT CevabÄ±:")
                st.write(response)

                # SonuÃ§ doÄŸrulama
                if st.checkbox("ğŸ” SonuÃ§ DoÄŸrulama"):
                    st.write(f"**KullanÄ±lan sÃ¼tun:** `{target_column}`")
                    if target_column in df_clean.columns:
                        st.write(f"**SÃ¼tun veri tipi:** `{df_clean[target_column].dtype}`")
                        st.write(f"**Ã–rnek deÄŸerler (ilk 10):**")
                        st.write(df_clean[target_column].dropna().head(10).tolist())

                        if pd.api.types.is_numeric_dtype(df_clean[target_column]):
                            st.write(
                                f"**DoÄŸrulama - {target_column} ortalamasÄ±:** `{df_clean[target_column].mean():.2f}`")
                            st.write(f"**DoÄŸrulama - {target_column} toplamÄ±:** `{df_clean[target_column].sum():.0f}`")
                        elif df_clean[target_column].dtype == 'object':
                            if not df_clean[target_column].dropna().empty:
                                top_value = df_clean[target_column].value_counts().index[0]
                                top_count = df_clean[target_column].value_counts().iloc[0]
                                st.write(
                                    f"**DoÄŸrulama - En sÄ±k {target_column} deÄŸeri:** `'{top_value}'` ({top_count} adet)")
                            else:
                                st.write(f"**DoÄŸrulama:** `{target_column}` sÃ¼tununda geÃ§erli deÄŸer bulunamadÄ±.")

                        # Yazar sorgusu iÃ§in manuel doÄŸrulama
                        if is_author_publication_count_query and author_name != "belirtilen yazar":
                            st.write(f"**Manuel DoÄŸrulama - '{author_name}' yayÄ±nlarÄ±:**")
                            # unidecode kullanarak manuel doÄŸrulama yap
                            search_term_normalized_manual = unidecode(author_name).lower()
                            df_filtered_manual = df_clean[
                                df_clean[target_column].astype(str).apply(lambda x: search_term_normalized_manual in unidecode(str(x)).lower() if pd.notna(x) else False)
                            ]
                            st.write(f"Manuel olarak bulunan yayÄ±n sayÄ±sÄ±: **{len(df_filtered_manual)}**")

                        # "En Ã§ok atÄ±f alan yayÄ±n" iÃ§in manuel doÄŸrulama
                        if ("en Ã§ok atÄ±f aldÄ±ÄŸÄ± yayÄ±n" in question_lower or "en Ã§ok atÄ±f alan yayÄ±n" in question_lower) \
                                and 'Ãœniversite AdÄ±' in df_clean.columns and 'Citation Count' in df_clean.columns and 'title' in df_clean.columns:

                            uni_search_term = ""
                            if "yaÅŸar Ã¼niversitesi" in unidecode(question_lower):
                                uni_search_term = "yaÅŸar Ã¼niversitesi"
                            elif "yaÅŸar" in unidecode(question_lower):
                                uni_search_term = "yaÅŸar"
                            elif "izmir ekonomi Ã¼niversitesi" in unidecode(question_lower):
                                uni_search_term = "izmir ekonomi Ã¼niversitesi"
                            elif "izmir ekonomi" in unidecode(question_lower):
                                uni_search_term = "izmir ekonomi"

                            df_filtered_uni_manual = df_clean
                            if uni_search_term:
                                search_uni_normalized_manual = unidecode(uni_search_term).lower()
                                df_filtered_uni_manual = df_clean[
                                    df_clean['Ãœniversite AdÄ±'].astype(str).apply(lambda x: search_uni_normalized_manual in unidecode(str(x)).lower() if pd.notna(x) else False)
                                ]

                            if not df_filtered_uni_manual.empty:
                                most_cited_manual = df_filtered_uni_manual.loc[
                                    df_filtered_uni_manual['Citation Count'].idxmax()]
                                st.write(
                                    f"**Manuel DoÄŸrulama - En Ã§ok atÄ±f alan yayÄ±n ({'genel' if not uni_search_term else uni_search_term}):**")
                                st.write(f"BaÅŸlÄ±k: **{most_cited_manual['title']}**")
                                st.write(f"AtÄ±f SayÄ±sÄ±: **{most_cited_manual['Citation Count']}**")
                            else:
                                st.write(f"**Manuel DoÄŸrulama:** Belirtilen kritere gÃ¶re yayÄ±n bulunamadÄ±.")
                    else:
                        st.warning(f"SeÃ§ilen sÃ¼tun `{target_column}` DataFrame'de bulunamadÄ±, doÄŸrulama yapÄ±lamadÄ±.")

            except Exception as e:
                st.error(f"âŒ Analiz sÄ±rasÄ±nda bir hata oluÅŸtu: **{e}**")
                logger.error(f"Agent error: {e}", exc_info=True)

    else:
        st.warning("â“ Soru hangi kategori ile ilgili olduÄŸu tespit edilemedi.")
        st.write("**LÃ¼tfen sorunuzu ÅŸu anahtar kelimelerle belirginleÅŸtirin:**")

        for col_name, col_info in ANALYZABLE_COLUMNS.items():
            if col_name in df_clean.columns:
                keywords_str = ', '.join(col_info['keywords'])
                st.write(f"â€¢ **{col_name}** iÃ§in: {keywords_str}")


# ğŸ“Š HÄ±zlÄ± istatistikler
st.subheader("ğŸ“Š HÄ±zlÄ± Ä°statistikler")

selected_stat_col = st.selectbox(
    "Ä°statistik gÃ¶rmek istediÄŸiniz sÃ¼tunu seÃ§in:",
    ['SeÃ§iniz'] + [col for col in ANALYZABLE_COLUMNS.keys() if col in df_clean.columns]
)

if selected_stat_col != 'SeÃ§iniz':
    st.write(f"**{selected_stat_col} sÃ¼tunu istatistikleri:**")

    if df_clean[selected_stat_col].dtype == 'object':
        value_counts = df_clean[selected_stat_col].value_counts().head(10)
        st.bar_chart(value_counts)
        st.write(f"**Toplam benzersiz deÄŸer:** {df_clean[selected_stat_col].nunique()}")
    else:
        st.write(df_clean[selected_stat_col].describe())
        st.histogram(df_clean[selected_stat_col].dropna())

# Sidebar - SÃ¼tun DetaylarÄ±
st.sidebar.subheader("ğŸ“‹ SÃ¼tun DetaylarÄ±")
for col_name, col_info in ANALYZABLE_COLUMNS.items():
    if col_name in df_clean.columns:
        with st.sidebar.expander(f"ğŸ” {col_name}"):
            st.write(f"**AÃ§Ä±klama:** {col_info['description']}")
            st.write(f"**Anahtar kelimeler:** {', '.join(col_info['keywords'])}")
            st.write(f"**Veri tipi:** {df_clean[col_name].dtype}")
            st.write(f"**Null deÄŸer:** {df_clean[col_name].isnull().sum()}")
            st.write(f"**Benzersiz deÄŸer:** {df_clean[col_name].nunique()}")