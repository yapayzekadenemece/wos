import requests
import math
import pandas as pd
import os

# --- AYARLAR ---
# API anahtarÄ±nÄ± bir ortam deÄŸiÅŸkeni (environment variable) olarak ayarlamak en iyi yÃ¶ntemdir.
# EÄŸer ortam deÄŸiÅŸkeni bulunamazsa, kod iÃ§indeki varsayÄ±lan deÄŸeri kullanÄ±r.
API_KEY = os.getenv("WOS_API_KEY", "2911c678b48cde2e576cc471cac3d27759f5328d")
BASE_URL = "https://api.clarivate.com/apis/wos-starter/v1/documents"
HEADERS = {"X-ApiKey": API_KEY}

# Ãœniversite listesi
universities = [
    "Reichman University", "Sabanci University", "TOBB Ekonomi ve Teknoloji University",
    "University of Navarra", "Universitat Internacional de Catalunya (UIC)",
    "Ozyegin University", "Kadir Has University", "Izmir Ekonomi Universitesi",
    "Jacobs University", "Ihsan Dogramaci Bilkent University", "Bahcesehir University",
    "Atilim University", "Koc University", "Universitat Ramon Llull", "Yasar University"
]


# --- VERÄ° Ã‡EKME FONKSÄ°YONU ---
def fetch_all_data(universities_list):
    """
    Belirtilen Ã¼niversiteler iÃ§in Web of Science API'sinden tÃ¼m yayÄ±n verilerini Ã§eker.
    """
    all_items = []

    for uni in universities_list:
        print(f"\nâ³ {uni} iÃ§in veri Ã§ekme iÅŸlemi baÅŸlÄ±yor...")

        page = 1
        total_pages = 1

        while page <= total_pages:
            query = f'OG="{uni}" AND FPY=1900-2030'
            params = {"db": "WOS", "q": query, "limit": 50, "page": page}

            try:
                response = requests.get(BASE_URL, headers=HEADERS, params=params)
                response.raise_for_status()
                data = response.json()

                if page == 1:
                    metadata = data.get("metadata", {})
                    total_records = metadata.get("total", 0)
                    if total_records == 0:
                        print(f"âš ï¸ {uni} iÃ§in hiÃ§ kayÄ±t bulunamadÄ±.")
                        break

                    per_page = metadata.get("limit", 50)
                    total_pages = math.ceil(total_records / per_page)
                    print(f"ğŸ” Toplam {total_records} kayÄ±t {total_pages} sayfada bulundu.")

                print(f"ğŸ“„ Sayfa {page}/{total_pages} iÅŸleniyor...")

                page_hits = data.get("hits", [])
                for item in page_hits:
                    item["source_university"] = uni
                all_items.extend(page_hits)

                page += 1

            except requests.exceptions.HTTPError as http_err:
                print(f"âŒ HTTP HatasÄ±: {http_err} - {response.text}")
                break
            except Exception as err:
                print(f"âŒ Genel bir hata oluÅŸtu: {err}")
                break

    return all_items


# --- VERÄ° Ä°ÅLEME FONKSÄ°YONU ---
def process_data_to_dataframe(items):
    """
    Ã‡ekilen ham veriyi iÅŸleyerek temiz bir Pandas DataFrame'ine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    if not items:
        print("Ä°ÅŸlenecek veri bulunamadÄ±.")
        return pd.DataFrame()

    df = pd.json_normalize(items)

    required_cols = [
        'uid', 'title', 'types', 'sourceTypes', 'source.sourceTitle',
        'source.publishYear', 'source.volume', 'source.issue',
        'source.pages.range', 'names.authors', 'citations',
        'identifiers.doi', 'identifiers.issn', 'keywords.authorKeywords',
        'source_university'
    ]

    existing_cols = [col for col in required_cols if col in df.columns]
    df = df[existing_cols]

    def get_first_or_none(value):
        return value[0] if isinstance(value, list) and value else None

    for col in ['types', 'sourceTypes']:
        if col in df.columns:
            df[col] = df[col].apply(get_first_or_none)

    if 'keywords.authorKeywords' in df.columns:
        df['keywords.authorKeywords'] = df['keywords.authorKeywords'].apply(
            lambda x: ', '.join(x) if isinstance(x, list) and x else None
        )

    if 'names.authors' in df.columns:
        df = df.explode('names.authors').reset_index(drop=True)
        df['Author Display Name'] = df['names.authors'].apply(
            lambda x: x.get('displayName') if isinstance(x, dict) else None)
        df['Author WoS Standard'] = df['names.authors'].apply(
            lambda x: x.get('wosStandard') if isinstance(x, dict) else None)
        df['Author Researcher ID'] = df['names.authors'].apply(
            lambda x: x.get('researcherId') if isinstance(x, dict) else None)

    if 'citations' in df.columns:
        df['Citation DB'] = df['citations'].apply(lambda x: x[0].get('db') if isinstance(x, list) and x else None)
        df['Citation Count'] = df['citations'].apply(lambda x: x[0].get('count') if isinstance(x, list) and x else 0)

    df.rename(columns={
        'source_university': 'Ãœniversite AdÄ±',
        'title': 'BaÅŸlÄ±k',
        'source.sourceTitle': 'Kaynak BaÅŸlÄ±ÄŸÄ±',
        'source.publishYear': 'YayÄ±n YÄ±lÄ±',
        'identifiers.doi': 'DOI',
        'keywords.authorKeywords': 'Yazar Anahtar Kelimeleri'
    }, inplace=True)

    cols_to_drop = ['names.authors', 'citations']
    df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)

    return df


# --- ANA AKIÅ ---
if __name__ == "__main__":
    raw_data = fetch_all_data(universities)
    final_df = process_data_to_dataframe(raw_data)

    if not final_df.empty:
        print("\n--- Ä°ÅLENMÄ°Å VERÄ° Ã–NÄ°ZLEMESÄ° ---")

        preview_cols = ['Ãœniversite AdÄ±', 'Author Display Name', 'BaÅŸlÄ±k', 'Citation Count']
        existing_preview_cols = [col for col in preview_cols if col in final_df.columns]

        if existing_preview_cols:
            print(final_df[existing_preview_cols].head())
        else:
            print("Ã–nizleme iÃ§in gerekli sÃ¼tunlar oluÅŸturulamadÄ±.")

        try:
            output_filename = "wos_tum_universiteler.xlsx"
            final_df.to_excel(output_filename, index=False)
            print(f"\nâœ… Veriler baÅŸarÄ±yla '{output_filename}' dosyasÄ±na aktarÄ±ldÄ±.")
        except Exception as e:
            print(f"\nâŒ Dosyaya yazma hatasÄ±: {e}")